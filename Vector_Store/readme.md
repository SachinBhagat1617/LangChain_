
# ğŸ“˜ Vector Stores in LangChain (Detailed Notes & README)

## ğŸ“Œ Overview

This repository contains **detailed conceptual and practical notes on Vector Stores**, a **core building block of Retrieval-Augmented Generation (RAG)** systems using LangChain.

The notes explain:

* Why **vector stores are needed**
* How **semantic similarity** works using embeddings
* Difference between **Vector Stores vs Vector Databases**
* How LangChain provides a **common interface** for multiple vector stores
* Practical usage with **Chroma Vector Store**
* CRUD operations and semantic search using embeddings

---

## ğŸ§  Why Do We Need Vector Stores?

### âŒ Problem with Keyword-Based Search

Traditional systems rely on **keyword matching**, which fails in many real-world cases.

#### Example:

* Movie A: *My Name Is Khan*
* Movie B: *Kabhi Alvida Na Kehna*

They share:

* Same actor (Shah Rukh Khan)
* Same director (Karan Johar)
* Similar release time
* Drama genre

ğŸ‘‰ Keyword matching says **they are similar**,
but **story-wise they are completely different**.

---

### âœ… Solution: Semantic Similarity (Meaning-Based Search)

Instead of matching keywords, we compare the **meaning of text** (plots, descriptions).

This is done using **Embeddings**.

---

## ğŸ§© What Are Embeddings?

Embeddings are **numerical vector representations** of text that capture **semantic meaning**.

* Text â†’ Neural Network â†’ Vector (e.g., 512 dimensions)
* Similar meaning â†’ Vectors closer in space
* Different meaning â†’ Vectors far apart

Once converted to vectors, we can compute:

* **Cosine Similarity**
* **Angular Distance**

---

## ğŸ¯ Real-World Example: Movie Recommendation System

### Steps:

1. Collect movie plots (2000â€“3000 words each)
2. Generate embeddings for every plot
3. Store embeddings in a **Vector Store**
4. Compare vectors to find similar movies
5. Recommend movies with **highest semantic similarity**

---

## ğŸš§ Challenges Without Vector Stores

| Challenge            | Problem                                        |
| -------------------- | ---------------------------------------------- |
| Embedding Generation | Millions of texts                              |
| Storage              | Vectors donâ€™t fit relational DBs               |
| Search               | Linear search over millions of vectors is slow |

ğŸ‘‰ **Vector Stores solve all three problems efficiently**

---

## ğŸ“¦ What Is a Vector Store?

> A **Vector Store** is a system designed to **store, retrieve, and search numerical vectors efficiently**.

---

## ğŸ”‘ Core Features of Vector Stores

### 1ï¸âƒ£ Vector Storage

* Store embeddings
* Store associated **metadata** (IDs, labels, tags)
* Supports:

  * In-memory storage (fast, non-persistent)
  * Disk-based storage (persistent, scalable)

---

### 2ï¸âƒ£ Similarity Search

* Finds vectors closest to a query vector
* Uses cosine similarity or distance metrics

---

### 3ï¸âƒ£ Indexing (Very Important)

Indexing enables **fast similarity search**.

Instead of:

```
Compare query with 1,000,000 vectors âŒ
```

We do:

```
Cluster â†’ Narrow search â†’ Compare fewer vectors âœ…
```

Common techniques:

* Clustering-based indexing
* Approximate Nearest Neighbors (ANN)

---

### 4ï¸âƒ£ CRUD Operations

* Add vectors
* Update vectors
* Delete vectors
* Retrieve vectors

---

## ğŸ“Œ Common Use Cases

* Recommendation Systems
* Semantic Search
* Retrieval-Augmented Generation (RAG)
* Chatbots with memory
* Image / Audio / Multimedia search

---

## âš–ï¸ Vector Store vs Vector Database

### Vector Store

* Lightweight
* Focuses on:

  * Storage
  * Similarity search
* Ideal for:

  * Prototyping
  * Small-scale applications

**Example:** FAISS

---

### Vector Database

* Full-fledged database system
* Adds:

  * Persistence
  * Distributed architecture
  * Authentication & authorization
  * Backup & restore
  * High scalability

**Examples:**

* Chroma
* Pinecone
* Weaviate

ğŸ‘‰ **Every vector database is a vector store, but not vice versa**

---

## ğŸ”— Vector Stores in LangChain

LangChain provides **built-in wrappers** for popular vector stores.

### Supported Vector Stores:

* Chroma
* FAISS
* Pinecone
* Weaviate
* Qdrant

### Key Advantage

All vector stores share the **same interface**:

```python
from_documents()
add_documents()
similarity_search()
similarity_search_with_score()
```

ğŸ‘‰ You can **swap vector stores without changing business logic**

---

## ğŸ§ª Chroma Vector Store (Hands-on)

Chroma is:

* Lightweight
* Open-source
* Ideal for local development
* Small to medium-scale production

---

### Chroma Data Hierarchy

```
Tenant
 â””â”€â”€ Database
      â””â”€â”€ Collection
           â””â”€â”€ Documents
                â”œâ”€â”€ Embedding Vector
                â””â”€â”€ Metadata
```

---

## ğŸ› ï¸ Operations Demonstrated

### âœ… Creating Documents

Each document contains:

* `page_content` â†’ actual text
* `metadata` â†’ additional info (e.g., team name)

---

### âœ… Creating Vector Store

* Choose embedding model (e.g., OpenAI embeddings)
* Choose persistence directory
* Create collection

---

### âœ… Add Documents

Automatically:

* Generates embeddings
* Assigns unique document IDs

---

### âœ… View Stored Data

Retrieve:

* IDs
* Embeddings
* Documents
* Metadata

---

### âœ… Semantic Search

```python
similarity_search(query="Who is a bowler?", k=2)
```

Returns most semantically relevant documents.

---

### âœ… Search with Score

Lower distance score = higher similarity

---

### âœ… Metadata Filtering

Example:

```python
filter={"team": "Chennai Super Kings"}
```

---

### âœ… Update Document

Update using document ID

---

### âœ… Delete Document

Delete using document ID

---

## ğŸ“š Homework (Highly Recommended)

Try implementing the **same code** using:

* FAISS
* Pinecone

ğŸ‘‰ Youâ€™ll notice **almost zero code changes**, thanks to LangChainâ€™s common interface.

---

## ğŸ¯ Final Takeaway

* Vector Stores are **fundamental for RAG systems**
* Keyword search is **not enough**
* Semantic similarity powered by embeddings is the future
* LangChain simplifies vector store integration
* Chroma is perfect for learning and prototyping

---
Perfect ğŸ‘
Now Iâ€™ll **explain everything using a single, clean end-to-end code example**, and Iâ€™ll explain **each step in simple words** so you understand *why* we are doing it â€” not just *what*.

Weâ€™ll use:

* LangChain
* Chroma

This example covers:

* Embeddings
* Vector Store creation
* Adding documents
* Similarity search
* Metadata filtering
* Update & delete

---

# ğŸ§  Vector Stores Explained Using Code (LangChain + Chroma)

---

## 1ï¸âƒ£ Install Required Libraries

```bash
pip install langchain chromadb openai
```

ğŸ‘‰ These give us:

* LangChain â†’ framework
* Chroma â†’ vector store
* OpenAI â†’ embeddings model

---

## 2ï¸âƒ£ Import Required Classes

```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.schema import Document
```

### Why?

* `OpenAIEmbeddings` â†’ converts text â†’ vectors
* `Chroma` â†’ stores vectors + searches them
* `Document` â†’ standard LangChain text format

---

## 3ï¸âƒ£ Create Documents (Text + Metadata)

```python
docs = [
    Document(
        page_content="Virat Kohli is one of the best batsmen in IPL history.",
        metadata={"team": "RCB"}
    ),
    Document(
        page_content="MS Dhoni is a legendary captain and wicketkeeper.",
        metadata={"team": "CSK"}
    ),
    Document(
        page_content="Jasprit Bumrah is a fast bowler known for yorkers.",
        metadata={"team": "MI"}
    ),
    Document(
        page_content="Ravindra Jadeja is an all-rounder who bats and bowls.",
        metadata={"team": "CSK"}
    )
]
```

### ğŸ§  Concept

Each `Document` has:

* `page_content` â†’ text used for embeddings
* `metadata` â†’ extra info for filtering

---

## 4ï¸âƒ£ Create Embedding Model

```python
embedding = OpenAIEmbeddings()
```

### ğŸ§  What happens here?

* Text â†’ Neural Network â†’ Vector (e.g., 1536 numbers)
* Meaning is captured numerically

---

## 5ï¸âƒ£ Create Chroma Vector Store

```python
vectorstore = Chroma(
    collection_name="players",
    embedding_function=embedding,
    persist_directory="./chroma_db"
)
```

### ğŸ§  What is happening?

* `collection_name` â†’ like a table
* `persist_directory` â†’ data stored on disk
* Embeddings auto-generated when documents are added

---

## 6ï¸âƒ£ Add Documents to Vector Store

```python
ids = vectorstore.add_documents(docs)
print(ids)
```

### ğŸ§  Internally:

1. Text â†’ embeddings
2. Embeddings stored in Chroma
3. Each document gets a **unique ID**

---

## 7ï¸âƒ£ View Stored Data

```python
data = vectorstore.get(
    include=["documents", "metadatas"]
)
print(data)
```

### ğŸ§  You can see:

* Stored text
* Metadata
* Document IDs

---

## 8ï¸âƒ£ Semantic Similarity Search (Core Feature ğŸ”¥)

```python
results = vectorstore.similarity_search(
    query="Who is a bowler?",
    k=1
)

print(results[0].page_content)
```

### ğŸ§  What happens internally?

1. Query â†’ embedding
2. Query vector compared with all stored vectors
3. Cosine similarity used
4. Most similar vector returned

ğŸ‘‰ Output:

```
Jasprit Bumrah is a fast bowler known for yorkers.
```

---

## 9ï¸âƒ£ Similarity Search With Score

```python
results = vectorstore.similarity_search_with_score(
    query="Who is a bowler?",
    k=2
)

for doc, score in results:
    print(doc.page_content, " | Score:", score)
```

### ğŸ§  Important:

* **Lower score = more similar**
* Score represents vector distance

---

## ğŸ”Ÿ Metadata-Based Filtering

```python
results = vectorstore.similarity_search(
    query="",
    filter={"team": "CSK"}
)

for doc in results:
    print(doc.page_content)
```

### ğŸ§  Why this is powerful?

* Combine **semantic search + structured filtering**
* Very useful in RAG apps

ğŸ‘‰ Output:

```
MS Dhoni is a legendary captain...
Ravindra Jadeja is an all-rounder...
```

---

## 1ï¸âƒ£1ï¸âƒ£ Update an Existing Document

```python
doc_id = ids[0]

updated_doc = Document(
    page_content="Virat Kohli is a former RCB captain known for aggressive batting.",
    metadata={"team": "RCB"}
)

vectorstore.update_documents(
    ids=[doc_id],
    documents=[updated_doc]
)
```

### ğŸ§  Internally:

* Old vector deleted
* New embedding generated
* Same ID reused

---

## 1ï¸âƒ£2ï¸âƒ£ Delete a Document

```python
vectorstore.delete(ids=[doc_id])
```

### ğŸ§  Result:

* Vector removed
* Metadata removed
* Not returned in future searches

---

## ğŸ”„ How This Fits Into RAG

```
User Question
   â†“
Convert to Embedding
   â†“
Vector Store Similarity Search
   â†“
Relevant Context
   â†“
LLM Generates Answer
```

ğŸ‘‰ Vector Store is the **brain memory** of RAG.

---

## ğŸ¯ Key Takeaways (Interview Gold)

* Embeddings = meaning â†’ numbers
* Vector stores enable **semantic search**
* Chroma stores vectors efficiently
* LangChain provides **common interface**
* Same code works for FAISS / Pinecone / Weaviate



